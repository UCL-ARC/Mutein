#this version uses the ftp download account setup by the ega helpdesk for me
#due to pyega3 not working

#define dataset_id, subset_id list, login credentials
- include: "../config/sanger_ega_ftp_{$MUT_PLATFORM}.yml"

#recursive ftp download of each accession with ncftp
- action:
    name:  "download_accessions"
    exec:  "local"
    conda: "ncftp"

    #no input

    output:
        touch: "datasets/{%dataset_id}/{=subset_id}/.meta/{%name}.touch"

    shell: |
        ncftpget -f {%credentials} -RT datasets/{%dataset_id} {=subset_id}
        touch {%touch}

#test md5 of all ftp downloaded files
- action:
    name: "verify_ftp_downloads"
    exec: "qsub"

    ym:
        parallel: "8"
    
    qsub:
      time:  "1:00:00"
      mem:   "4G"
      cores: "1"
      maxrun: "40"

    input:
        #             eg datasets/sanger_ega_ftp/EGAD00001001123/13726_1.cram.cip
        accession_file: "datasets/{%dataset_id}/{=subset_id}/{*accession}.cip"

    output:
        touch:          "datasets/{%dataset_id}/{=subset_id}/.meta/verify_ftp_downloads.{*accession}.touch"

    shell: |
        md5_file="{%accession_file}.md5"
        file ${md5_file}   #error if missing
        expected=$(cat "${md5_file}")
        observed=$(cat "{%accession_file}" | md5sum | awk '{print $1}')
        [[ "${expected}" == "${observed}" ]] && touch {%touch}

# here copy from myriad to cs - using rsync
# I used a single manually entered command running from barker on CS cluster:
# while true ; do rsync -av myriad:/lustre/scratch/scratch/ccaervi/549_mutein/datasets/sanger_ega_ftp . ; sleep 300 ; done
# executed in the folder /SAN/medic/Mutein/549_mutein/datasets/sanger_ega_myriad_rsync

# decrypt files
- action:
    name: "decrypt_crams"
    exec: "parallel"

    ym:
        parallel: "8"

    qsub:
      time:  "4:00:00"
      mem:   "4G"
      cores: "1"
      maxrun: "10"

    input:
        #             eg datasets/sanger_ega_ftp/EGAD00001001123/13726_1.cram.cip
        cip_file:     "datasets/{%dataset_id}/{=subset_id}/{*accession}.cip"
        is_verified:  "datasets/{%dataset_id}/{=subset_id}/.meta/verify_ftp_downloads.{*accession}.touch"

    output:
        cram_file:    "datasets/{%dataset_id}/{=subset_id}/{*accession}"

    shell: |
        openssl enc -d -aes-256-cbc \
            -in {%cip_file}   \
            -out {%cram_file} \
            -k $(cat {%decryption_password}) -md sha256

# truncate the encrypted versions to save space
- action:
    name: "truncate_cips"
    exec: "local"
    run:  "never" #comment out to activate
    
    ym:
        aggregate: "20"

    input:
        cip_file:  "datasets/{%dataset_id}/{=subset_id}/{*accession}.cip"

    output:
        touch:     "datasets/{%dataset_id}/{=subset_id}/.meta/{%name}.{*accession}.cip.touch"

    shell: |
        mutein truncate {%cip_file}
        touch {%touch}

#remove "#"" from file names and reorganised into subsets etc
