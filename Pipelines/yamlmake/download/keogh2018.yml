#define dataset_id and subset_list
- include: "../config/keogh2018.yml"

#download list of accession names
- action:
    name:  "download_accession_list"
    exec:  "local"
    conda: "enabrowsertools"

    #no input files

    output:
        accession_file: "datasets/{%dataset_id}/{=subset_id}/.meta/accession_list"

    #grab list of sra run accessions from NCBI (US site)
    shell: |
        esearch -db sra -query {=subset_id} \
        | efetch -format xml \
        | xtract -pattern RUN -element PRIMARY_ID \
        | awk '{{print $1}}' \
        | sort \
        > {%accession_file}

- action:
    name: "create_accession_folders"
    exec:  "local"

    input:
        #spawn one job per subset_id, currently there's only one
        accession_list: "datasets/{%dataset_id}/{=subset_id}/.meta/accession_list"

    output:
        touch: "datasets/{%dataset_id}/{=subset_id}/.meta/create_accession_folders.touch"

    shell: |
        for acc in $(cat {%accession_list})
        do
            mkdir -p datasets/{%dataset_id}/{=subset_id}/${acc}/.meta
            touch datasets/{%dataset_id}/{=subset_id}/${acc}/.meta/download_pending
        done
        touch {%touch}

- action:
    name:  "download_accessions"
    exec:  "local"
    conda: "enabrowsertools"

    input:
        #avoid using dir as the input as its mtime updates when any of its contents change
        download_trigger: "datasets/{%dataset_id}/{=subset_id}/{*accession}/.meta/download_pending"

    output:
        read1: "datasets/{%dataset_id}/{=subset_id}/{*accession}/{*accession}_1.fastq.gz"
        read2: "datasets/{%dataset_id}/{=subset_id}/{*accession}/{*accession}_2.fastq.gz"
        #note: most also have {*accession}.fastq.gz as well

    shell: |
        cd datasets/{%dataset_id}/{=subset_id}/{*accession}
        enaDataGet -f fastq {*accession}

#make sure user has downloaded the metadata file from:
#https://www.ncbi.nlm.nih.gov/sra/?term=SRP159015
# ==> "Send results to run selector"
# ==> "Metadata"
- action:
    name: "require_meta_data"
    exec: "local"

    input:
        metadata: "datasets/{%dataset_id}/{=subset_id}/.meta/SraRunTable.txt"

    output:
        touch:    "datasets/{%dataset_id}/{=subset_id}/.meta/{%name}.touch"

    shell: |
        touch {%touch}

#extract sample information from metadata
- action:
    name: "extract_sample_info"
    exec: "local"
    conda: "main"

    input:
        metadata: "datasets/{%dataset_id}/{=subset_id}/.meta/SraRunTable.txt"
        download_trigger: "datasets/{%dataset_id}/{=subset_id}/{*accession}/.meta/download_pending"

    output:
        acc_meta:  "datasets/{%dataset_id}/{=subset_id}/{*accession}/.meta/accession_metadata"
        sample_no: "datasets/{%dataset_id}/{=subset_id}/{*accession}/.meta/sample_number"
        all_acc_list:  "datasets/{%dataset_id}/{=subset_id}/{*accession}/.meta/all_sample_accessions"
        other_acc_list:  "datasets/{%dataset_id}/{=subset_id}/{*accession}/.meta/other_sample_accessions"

    shell: |
        #extract accession's metadata line from metadata file
        tail -n +2 {%metadata} | grep -w -e '^{*accession}' > {%acc_meta}

        #extract sample number (at csv column 22 as SAMPLENUMBER_XXX_XXX
        cat {%acc_meta} | mutein cut -f 22 | cut -d_ -f1 > {%sample_no}
        sample=$(cat {%sample_no})

        #find all accessions with the same sample number
        tail -n +2 {%metadata} | mutein cut -f 1 22 -o '_' | tr '_' ' ' | cut -d' ' -f1,2 \
        | grep -w -e "${sample}" \
        | awk '{print $1}' \
        > {%all_acc_list}

        #exclude the current accession from the list
        set +o pipefail
        cat {%all_acc_list} \
        | grep -wv -e '{*accession}' | cat \
        > {%other_acc_list}