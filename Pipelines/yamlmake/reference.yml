#download the reference files into a temporary location
- action:
    name: "download_reference"

    readme_url: "{%ref/base_url}/{%ref/readme}"
    md5_url:    "{%ref/base_url}/{%ref/md5}"
    fasta_url:  "{%ref/base_url}/{%ref/fasta}"

    #no input

    output:
      readme: "{%ref/tmp_dir}/{%ref/readme}"
      md5:    "{%ref/tmp_dir}/{%ref/md5}"
      fasta:  "{%ref/tmp_dir}/{%ref/fasta}"

    #download ensuring an overwrite and timestamp update of the outputs
    shell: |
      wget -O - {%readme_url} > {%readme} 
      wget -O - {%md5_url}    > {%md5}
      wget -O - {%fasta_url}  > {%fasta}

#do the md5 check of the reference file
- action:
    name: "check_reference"

    input:
      readme: "{%ref/tmp_dir}/{%ref/readme}"
      md5:    "{%ref/tmp_dir}/{%ref/md5}"
      fasta:  "{%ref/tmp_dir}/{%ref/fasta}"

    output:
      md5check: "{%ref/tmp_dir}/MD5.txt"

    #extract and check just the relevant checksum
    shell: |
        cat {%md5} | grep -e '{%ref/fasta}' > {%md5check} 
        cd {%ref/tmp_dir} && md5sum --check MD5.txt

#convert gzip into an indexed bgzip format
- action:
    name:  "create_bgzip"
    exec:  "qsub"
    conda: "bwa"
    qsub:
        time:  "1:00:00"
        mem:   "6G"
        tmpfs: "10G"
        cores: "1"

    input:
        orig_fasta: "{%ref/tmp_dir}/{%ref/fasta}" #gzip compressed fasta
        md5check:   "{%ref/tmp_dir}/MD5.txt"      #require that MD5 was checked

    output:
        fasta_bgz: "{%ref/fasta_bgz}"     #bgzip compressed fasta
        fasta_gzi: "{%ref/fasta_gzi}"

    shell: |
        gunzip --to-stdout {%orig_fasta} | bgzip -i -I {%fasta_gzi} > {%fasta_bgz}

#create fasta file index with samtools
- action:
    name:  "create_fai"
    exec:  "qsub"
    conda: "bwa"
    qsub:
        time:  "1:00:00"
        mem:   "6G"
        tmpfs: "10G"
        cores: "1"

    input:
        fasta_bgz: "{%ref/fasta_bgz}"

    output:
        fasta_fai: "{%ref/fasta_fai}"

    shell: |
        samtools faidx {%fasta_bgz}

#create bwa index
- action:
    name: "create_bwtsw"
    exec:  "qsub"
    conda: "bwa"
    qsub:
        time:  "2:00:00"
        mem:   "6G"
        tmpfs: "10G"
        cores: "1"

    #file extensions of all the index files bwa will create
    exts: [ "bwt","pac","ann","amb","sa" ]

    input:
        fasta_bgz: "{%ref/fasta_bgz}"

    output:
        bwt_indexes: "{%ref/fasta_bgz}.{-exts}"

    shell: |
        bwa index -a bwtsw {%fasta_bgz}

#create gatk index
- action:
    name: "create_gatk_dict"
    exec:  "qsub"
    conda: "gatk4"
    qsub:
        time:  "1:00:00"
        mem:   "6G"
        tmpfs: "10G"
        cores: "1"

    input:
        fasta_bgz: "{%ref/fasta_bgz}"

    output:
        fasta_dict: "{%ref/fasta_dict}"

    shell: |
        gatk CreateSequenceDictionary -R {%fasta_bgz} -O {%fasta_dict}

#download the GFF3 annotation file
- action:
    name: "download_annotation"

    gff3_url: "{%ref/annot_url}/{%ref/annot_gff3}"
    chk_url:  "{%ref/annot_url}/{%ref/annot_chk}"

    #no input

    output:
        gff3: "{%ref/annot_dir}/{%ref/annot_gff3}"
        chk:  "{%ref/annot_dir}/{%ref/annot_chk}"

    shell: |
        wget -O - {%gff3_url} > {%gff3}
        wget -O - {%chk_url}  > {%chk}

#verify the GFF3 annotation file
- action:
    name: "verify_annotation"

    input:
        gff3: "{%ref/annot_dir}/{%ref/annot_gff3}"
        chk:  "{%ref/annot_dir}/{%ref/annot_chk}"

    output:
        touch: "{%ref/annot_dir}/{%name}.touch"

    shell: |
        expected=$(cat {%chk} | grep '{%ref/annot_gff3}' | awk '{print $1,$2}')
        observed=$(sum {%gff3})

        if [[ ! "${observed}" == "${expected}" ]] ; then
            echo "Got checksum ${observed} but expected ${expected}"
            exit 1
        fi

        touch {%touch}

#download dbsnp vcf for use with base quality score recalibration
- action:
    name: "download_dbsnp"
    exec: "local"

    vcf_url: "{%ref/dbsnp_url}/{%ref/dbsnp_vcf}"
    chk_url: "{%ref/dbsnp_url}/{%ref/dbsnp_md5}"

    #no input

    output:
        vcf: "{%ref/dbsnp_dir}/{%ref/dbsnp_vcf}"
        chk: "{%ref/dbsnp_dir}/{%ref/dbsnp_md5}"

    shell: |
        wget -O - {%vcf_url} > {%vcf}
        wget -O - {%chk_url} > {%chk}

#check dbsnp md5s
- action:
    name: "check_dbsnp"

    input:
        vcf: "{%ref/dbsnp_dir}/{%ref/dbsnp_vcf}"
        chk: "{%ref/dbsnp_dir}/{%ref/dbsnp_md5}"

    output:
        touch: "{%ref/dbsnp_dir}/{%name}.touch"

    #check both md5
    shell: |
        cd {%ref/dbsnp_dir}
        md5sum --check {%ref/dbsnp_md5}
        cd -
        touch {%touch}

#download assembly report to enable conversion from dbsnp to ucsc naming
- action:
    name: "download_assembly_report"

    report_url: "{%ref/assembly_report_url}/{%ref/assembly_report_file}"

    output:
        report: "{%ref/dbsnp_dir}/{%ref/assembly_report_file}"

    shell: |
        wget -O - {%report_url} > {%report}

#generate ncbi to ucsc name mapping file
- action:
    name: "generate_name_mapping"

    input:
        report: "{%ref/dbsnp_dir}/{%ref/assembly_report_file}"

    output:
        mapping: "{%ref/dbsnp_dir}/{%ref/assembly_name_mapping}"

    shell: |
        cat {%report} | grep -v '^#' | cut -f7,10 | grep -v 'na' > {%mapping}

#change the chromosomes names in the dbsnp vcf to match the reference
- action:
    name:  "rename_vcf_chromosomes"
    conda: "bcftools"

    input:
        dbsnp:   "{%ref/dbsnp_dir}/{%ref/dbsnp_vcf}"
        mapping: "{%ref/dbsnp_dir}/{%ref/assembly_name_mapping}"

    output:
        final: "{%ref/dbsnp_dir}/{%ref/final_vcf}"

    shell: |
        bcftools annotate \
            --rename-chrs {%mapping} \
            {%dbsnp} \
            -Oz -o {%final}

#tabix index the fixed vcf
- action:
    name:  "index_vcf"
    conda: "bwa"

    input:
        final: "{%ref/dbsnp_dir}/{%ref/final_vcf}"

    output:
        index: "{%ref/dbsnp_dir}/{%ref/final_vcf}.tbi"

    shell: |
        tabix -p vcf {%final}

#download google cloud gatk resource bundle
#https://gatk.broadinstitute.org/hc/en-us/articles/360035890811-Resource-bundle
#https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0/
- action:
    name:  "download_gatk_bundle"
    conda: "gsutil"

    output:
        touch: "resources/gatk_bundle/.meta/{%name}.touch"

    shell: |
        # gsutil -m cp -r \
        #     "gs://genomics-public-data/resources/broad/hg38/v0" \
        #     resources/gatk_bundle

        touch {%touch}

#decompress the reference into a plain fasta for gatk3
- action:
    name:  "uncompress_reference"
    exec:  "local"

    qsub:
        time:  "1:00:00"
        mem:   "6G"
        tmpfs: "10G"
        cores: "1"

    input:
        fasta_bgz: "{%ref/fasta_bgz}"     #bgzip compressed fasta

    output:
        fasta_plain: "{%ref/uncompressed}"     #plain fasta

    shell: |
        gunzip --to-stdout {%fasta_bgz} > {%fasta_plain}

#create fasta file index with samtools
- action:
    name:  "create_fai_uncompressed"
    exec:  "local"
    conda: "bwa"
    
    qsub:
        time:  "1:00:00"
        mem:   "6G"
        tmpfs: "10G"
        cores: "1"

    input:
        fasta: "{%ref/uncompressed}"

    output:
        index: "{%ref/uncompressed_fai}"

    shell: |
        samtools faidx {%fasta}
