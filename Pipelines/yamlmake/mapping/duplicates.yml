#mark duplicates on the query (ie read name) sorted reads
#no recommended for amplicon sequencing data as this generates many reads with the same
#start/end positions by design, but bait capture enrichment of normal fragmented DNA
#should not and can be deduplicated as normal
#see C. Xu / Computational and Structural Biotechnology Journal 16 (2018) 15â€“24
- action:
    name:  "mark_duplicates"
    exec:  "qsub"
    conda: "gatk4"

    qsub: 
        time:  "24:00:00"
        mem:   "6G"
        tmpfs: "20G"
        cores: "2"

    input:
        ibam:    "processed/{%dataset_id}/{=subset_id}/{*accession}/{*accession}_all_sort.bam"

    output:
        obam:    "processed/{%dataset_id}/{=subset_id}/{*accession}/{*accession}_dedup.bam"
        metrics: "processed/{%dataset_id}/{=subset_id}/{*accession}/{*accession}_duplicate_metrics"

    shell: |
        MY_GATK_TMP=${TMPDIR}/${USER}-${RANDOM}${RANDOM}
        mkdir -p ${MY_GATK_TMP}
        gatk --java-options "-Xmx8g" MarkDuplicates \
            --TMP_DIR ${MY_GATK_TMP} \
            --READ_NAME_REGEX {%read_name_regex} \
            --ASSUME_SORT_ORDER queryname \
            -I {%ibam} \
            -O {%obam} \
            -M {%metrics}

#following duplicate marking change sort order from read name to mapping position
#then index the new bam
# note: for keogh the @RG PL:ILLUMINA tags were inserted at this point using
# | samtools addreplacerg -u -w \
#   -r 'ID:{%dataset_id}_{=subset_id}_{*accession}' \
#   -r 'SM:{%dataset_id}_{=subset_id}_{*accession}' \
#   -r 'PL:{%platform}' \
#   - \
#but the production pipeline inserts these tags in mapping/mapping.yml:samtools_merge
- action:
    name:  "sort_by_posn_then_index"
    exec:  "qsub"
    conda: "bwa"

    qsub: 
        time:  "24:00:00"
        mem:   "6G"
        tmpfs: "20G"
        cores: "3"

    input:
        ibam:  "processed/{%dataset_id}/{=subset_id}/{*accession}/{*accession}_dedup.bam"

    output:
        obam:  "processed/{%dataset_id}/{=subset_id}/{*accession}/{*accession}_posn_sort.bam"
        indx:  "processed/{%dataset_id}/{=subset_id}/{*accession}/{*accession}_posn_sort.bam.bai"

    #sort mapped reads by mapping position, output to bam file
    shell: |
        SAMTOOLS_TMP=${TMPDIR}/${USER}-${RANDOM}${RANDOM}
        mkdir -p ${SAMTOOLS_TMP}
        EXTRA_THREADS=$(({%qsub/cores}-1))

        samtools view -uh {%ibam} \
        | samtools sort -@ ${EXTRA_THREADS} -T ${SAMTOOLS_TMP} -O bam -m 2G - \
        > {%obam}

        samtools index -@ ${EXTRA_THREADS} {%obam}

#truncate _dedup bams
- action:
    name:  "truncate_dedup_bam"
    exec:  "local"
    conda: "main"
    run:   "never"

    input:
        dedup:   "processed/{%dataset_id}/{=subset_id}/{*accession}/{*accession}_dedup.bam"

    output:
        touch:  "processed/{%dataset_id}/{=subset_id}/{*accession}/{%name}.touch"

    shell: |
        #truncate deduped bam
        mutein truncate "{%dedup}"

        #signal truncation was carried out
        touch {%touch}
