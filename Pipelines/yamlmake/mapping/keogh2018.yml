#define dataset_id and subset_list
- include: "../config/keogh2018.yml"

#map paired reads to reference with bwa, add ID tag, sort, output to bam
- action:
    name:  "bwa_mem_pair"
    exec:  "qsub"
    conda: "bwa"

    qsub: 
        time:  "24:00:00" #run time seems to depend on network traffic
        mem:   "10G"
        tmpfs: "20G"
        cores: "2"

    input:
        read1: "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_1.fastq.gz"
        read2: "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_2.fastq.gz"

    output:
        bam:   "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_pair_sort.bam"

    #map with bwa mem, add readgroup tag to say "these are all from the same sample"
    #sort mapped reads by mapping position, output to bam file
    shell: |
        SAMTOOLS_TMP=${TMPDIR}/${USER}-${RANDOM}${RANDOM}
        mkdir -p ${SAMTOOLS_TMP}

        bwa mem -t {%qsub/cores} {%ref/fasta_bgz} {%read1} {%read2} \
        | samtools addreplacerg \
          -r 'ID:{%dataset_id}_{*subset_id}_{*accession}' \
          -r 'SM:{%dataset_id}_{*subset_id}_{*accession}' - \
        | samtools sort -T ${SAMTOOLS_TMP} -O bam -m 2G - \
        > {%bam}

#map single reads to reference with bwa, add ID tag, sort, output to bam
#note not all samples have a single reads fastq.gz
- action:
    name:  "bwa_mem_sing"
    exec:  "qsub"
    conda: "bwa"

    qsub: 
        time:  "24:00:00" #run time seems to depend on network traffic
        mem:   "10G"
        tmpfs: "20G"
        cores: "2"

    input:
        read: "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}.fastq.gz"

    output:
        bam:  "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_sing_sort.bam"

    #map with bwa mem, add readgroup tag to say "these are all from the same sample"
    #sort mapped reads by mapping position, output to bam file
    shell: |
        SAMTOOLS_TMP=${TMPDIR}/${USER}-${RANDOM}${RANDOM}
        mkdir -p ${SAMTOOLS_TMP}

        bwa mem -t {%qsub/cores} {%ref/fasta_bgz} {%read} \
        | samtools addreplacerg \
          -r 'ID:{%dataset_id}_{*subset_id}_{*accession}' \
          -r 'SM:{%dataset_id}_{*subset_id}_{*accession}' - \
        | samtools sort -T ${SAMTOOLS_TMP} -O bam -m 2G - \
        > {%bam}

#merge single and paired read alignments into single bam
#note this action misses samples lacking single reads, but next action handles that
- action:
    name:  "samtools_merge"
    exec:  "qsub"
    conda: "bwa"

    qsub: 
        time:  "24:00:00" #run time seems to depend on network traffic
        mem:   "6G"
        cores: "4"

    input:
        sing:  "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_sing_sort.bam"
        pair:  "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_pair_sort.bam"

    output:
        all:   "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_all_sort.bam"

    shell: |
        samtools merge -c -p --threads $(({%qsub/cores}-1)) -o - {%sing} {%pair} > {%all}

#handle samples where there is no single read file
#therefore previous action did not run and all_sort is still missing
#fix by symlinking to the paired read bam from the merged filename
- action:
    name:  "fake_merge"
    exec:  "local"
    conda: "bwa"

    qsub: 
        time:  "24:00:00" #run time seems to depend on network traffic
        mem:   "6G"
        cores: "4"

    input:
        pair:  "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_pair_sort.bam"

    output:
        all:   "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_all_sort.bam"

    #make sure symlink is never created if single file somehow does exist
    shell: |
        paired="{%pair}"

        if [[ ! -f "${paired/_pair_/_sing_}" ]] ; then
            cd "processed/{%dataset_id}/{*subset_id}/{*accession}"
            ln -s "{*accession}_pair_sort.bam" "{*accession}_all_sort.bam"
        fi

#index the merged bam
- action:
    name:  "samtools_index"
    exec:  "qsub"
    conda: "bwa"

    qsub:
        time:  "24:00:00" #run time seems to depend on network traffic
        mem:   "6G"
        cores: "3"

    input:
        all:   "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_all_sort.bam"

    output:
        ind:   "processed/{%dataset_id}/{*subset_id}/{*accession}/{*accession}_all_sort.bam.bai"

    shell: |
        samtools index --threads $(({%qsub/cores}-1)) {%all}
